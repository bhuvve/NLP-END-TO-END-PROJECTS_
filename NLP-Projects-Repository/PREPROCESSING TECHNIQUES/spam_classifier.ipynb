{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spam classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC9dYAkN5azH"
      },
      "source": [
        "####**Importing necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jijhsIpS4Otg"
      },
      "source": [
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQrSLiLw7M6U"
      },
      "source": [
        "####**Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "TgG_TESj4SIn",
        "outputId": "d3dfc9cf-de45-465f-f65f-5b5fe4e81dde"
      },
      "source": [
        "df = pd.read_csv(\"/content/SMSSpamCollection\", sep=\"\\t\", header=None)\n",
        "\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5572, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0                                                  1\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA6MpW324SEH"
      },
      "source": [
        "cols = ['label', 'context']\n",
        "df.columns = cols"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YeRgTTPR4SB1",
        "outputId": "1279ba7e-a983-420a-e2ef-c461c793a190"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                            context\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_4rTt6w5ekY"
      },
      "source": [
        "####**Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_WuRgad4R_f",
        "outputId": "4fb5cef4-f6f3-410d-a55a-8f2e6270446f"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   label    5572 non-null   object\n",
            " 1   context  5572 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 87.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjzV5bnd4R8_",
        "outputId": "8854ff35-1694-456e-b7a6-b5a448829dc1"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label      0\n",
              "context    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0CguTl96q56",
        "outputId": "76e8e538-d5a7-4bc4-aaa7-f6396c9d93f7"
      },
      "source": [
        "df['label'].value_counts()\n",
        "\n",
        "# we can see it's kind of an imbalanced dataset but in this tutorial we don't care, we just want to learn an end to end nlp project"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ham     4825\n",
              "spam     747\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zjEl6WDw5UVy",
        "outputId": "54c296d3-941a-417d-d4a4-cc2822e0fc3d"
      },
      "source": [
        "df['length'] = df['context'].apply(lambda x: len(x))\n",
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>context</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                            context  length\n",
              "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
              "1   ham                      Ok lar... Joking wif u oni...      29\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
              "3   ham  U dun say so early hor... U c already then say...      49\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...      61"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoUPyyPR5USK",
        "outputId": "70facee2-2982-425f-f902-4031d826a5ac"
      },
      "source": [
        "# calculating max length of sentences\n",
        "lens = []\n",
        "for sentence in df['context']:\n",
        "    lens.append(len(sentence))\n",
        "\n",
        "print(max(lens))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "910\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4hfqLgw6Vc2"
      },
      "source": [
        "####**Text Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umkuHJEy5UP_"
      },
      "source": [
        "def convert_to_lower(text):\n",
        "    return text.lower()\n",
        "\n",
        "def remove_numbers(text):\n",
        "    number_pattern = r'\\d+'\n",
        "    without_number = re.sub(pattern=number_pattern, repl=\" \", string=text)\n",
        "    return without_number\n",
        "\n",
        "def lemmatizing(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = word_tokenize(text)\n",
        "    for i in range(len(tokens)):\n",
        "        lemma_word = lemmatizer.lemmatize(tokens[i])\n",
        "        tokens[i] = lemma_word\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    removed = []\n",
        "    stop_words = list(stopwords.words(\"english\"))\n",
        "    tokens = word_tokenize(text)\n",
        "    for i in range(len(tokens)):\n",
        "        if tokens[i] not in stop_words:\n",
        "            removed.append(tokens[i])\n",
        "    return \" \".join(removed)\n",
        "\n",
        "def remove_extra_white_spaces(text):\n",
        "    single_char_pattern = r'\\s+[a-zA-Z]\\s+'\n",
        "    without_sc = re.sub(pattern=single_char_pattern, repl=\" \", string=text)\n",
        "    return without_sc"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7XP4QFu5UNu"
      },
      "source": [
        "df['context'] = df['context'].apply(lambda x: convert_to_lower(x))\n",
        "df['context'] = df['context'].apply(lambda x: remove_numbers(x))\n",
        "df['context'] = df['context'].apply(lambda x: remove_punctuation(x))\n",
        "df['context'] = df['context'].apply(lambda x: remove_stopwords(x))\n",
        "df['context'] = df['context'].apply(lambda x: remove_extra_white_spaces(x))\n",
        "df['context'] = df['context'].apply(lambda x: lemmatizing(x))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Iw1V0Prq7cBD",
        "outputId": "ef4a4fbd-86c1-41c5-8344-492cb168f086"
      },
      "source": [
        "df['length_after_cleaning'] = df['context'].apply(lambda x: len(x))\n",
        "df.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>context</th>\n",
              "      <th>length</th>\n",
              "      <th>length_after_cleaning</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go jurong point crazy available bugis great wo...</td>\n",
              "      <td>111</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar joking wif oni</td>\n",
              "      <td>29</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
              "      <td>155</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say early hor c already say</td>\n",
              "      <td>49</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah dont think go usf life around though</td>\n",
              "      <td>61</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  ... length_after_cleaning\n",
              "0   ham  ...                    78\n",
              "1   ham  ...                    21\n",
              "2  spam  ...                   101\n",
              "3   ham  ...                    33\n",
              "4   ham  ...                    40\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxfY9VBB9Trb"
      },
      "source": [
        "####**Vectorization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry2SXwXt8x7G"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UzcS6A2T9wv9",
        "outputId": "0dd690f8-fc9f-4f66-a24e-4d9a1ae3cf28"
      },
      "source": [
        "# converting labels to numbers\n",
        "\n",
        "label_map = {\n",
        "    'ham': 0,\n",
        "    'spam': 1,\n",
        "}\n",
        "\n",
        "df['label'] = df['label'].map(label_map)\n",
        "df.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>context</th>\n",
              "      <th>length</th>\n",
              "      <th>length_after_cleaning</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>go jurong point crazy available bugis great wo...</td>\n",
              "      <td>111</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>ok lar joking wif oni</td>\n",
              "      <td>29</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
              "      <td>155</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>u dun say early hor c already say</td>\n",
              "      <td>49</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>nah dont think go usf life around though</td>\n",
              "      <td>61</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  ... length_after_cleaning\n",
              "0      0  ...                    78\n",
              "1      0  ...                    21\n",
              "2      1  ...                   101\n",
              "3      0  ...                    33\n",
              "4      0  ...                    40\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q630OpeY9Wi6"
      },
      "source": [
        "# COUNT VECTORIZATION\n",
        "\n",
        "cv = CountVectorizer()\n",
        "X_cv = cv.fit_transform(df['context'])\n",
        "X_cv = X_cv.toarray()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG8GFON6-YO7"
      },
      "source": [
        "# NGRAM VECTORIZATION\n",
        "\n",
        "cv_ngram = CountVectorizer(ngram_range=(1,3))\n",
        "X_cv_ngram = cv_ngram.fit_transform(df['context'])\n",
        "X_cv_ngram = X_cv_ngram.toarray()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEVPIo5n9Weo"
      },
      "source": [
        "# TFIDF VECTORIZATION\n",
        "\n",
        "tf = TfidfVectorizer()\n",
        "X_tf = tf.fit_transform(df['context'])\n",
        "X_tf = X_tf.toarray()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sP3fKedT9Wcg",
        "outputId": "204c8044-528f-436f-8c2e-ba9e0fa3e021"
      },
      "source": [
        "X_cv.shape, X_cv_ngram.shape, X_tf.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5572, 7906), (5572, 68742), (5572, 7906))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BEi945g-7aj"
      },
      "source": [
        "####**Splitting data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogxYice19WaP"
      },
      "source": [
        "X_train_cv, X_test_cv, y_train_cv, y_test_cv = train_test_split(X_cv, df['label'].values, test_size=0.2)\n",
        "X_train_ngram, X_test_ngram, y_train_ngram, y_test_ngram = train_test_split(X_cv_ngram, df['label'].values, test_size=0.2)\n",
        "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(X_tf, df['label'].values, test_size=0.2)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WiEmNzV_o2z"
      },
      "source": [
        "####**Machine Learning Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPPIM5IY-9qI"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj7UvllnGsC4"
      },
      "source": [
        "**using Count vectorized matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v05gADsX-9md",
        "outputId": "88c284f5-2a61-4232-ccae-ea41fd9331ae"
      },
      "source": [
        "naiveBayes = GaussianNB()\n",
        "naiveBayes.fit(X_train_cv, y_train_cv)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trtttVRV-9ke",
        "outputId": "4d973678-d450-4116-b8ac-3935091d83a3"
      },
      "source": [
        "y_pred_cv = naiveBayes.predict(X_test_cv)\n",
        "\n",
        "print(accuracy_score(y_test_cv, y_pred_cv))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8762331838565023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFG9RsHkGxs_"
      },
      "source": [
        "**using n-gram vectorized matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pyMqTNW-9iT",
        "outputId": "b3d0be85-4cb7-40cc-9f2c-cbf229869d29"
      },
      "source": [
        "naiveBayes.fit(X_train_ngram, y_train_ngram)\n",
        "\n",
        "y_pred_ngram = naiveBayes.predict(X_test_ngram)\n",
        "\n",
        "print(accuracy_score(y_test_ngram, y_pred_ngram))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9264573991031391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmqLy6bCG0uI"
      },
      "source": [
        "**using tfidf vectorized matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5LMIVBdGOex",
        "outputId": "55968247-3ee3-49dc-db44-10ab1513dd59"
      },
      "source": [
        "naiveBayes.fit(X_train_tf, y_train_tf)\n",
        "\n",
        "y_pred_tf = naiveBayes.predict(X_test_tf)\n",
        "\n",
        "print(accuracy_score(y_test_tf, y_pred_tf))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8807174887892377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l1W22BbGd3e"
      },
      "source": [
        "####**Therefore, we got around 93% accuracy with Ngram Document Matrix**"
      ]
    }
  ]
}